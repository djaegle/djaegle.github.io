<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>{{ site.name }}</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
</head>

<body>
  <main class="container">
    <header class="hero">
      <img class="profile-image" alt="Drew Jaegle" src="images/drew_photo.png">
      <h1>Andrew (Drew) Jaegle</h1>
    </header>

    <hr>

    <section class="bio">
      <p>
        I'm Head of AI at <a href="https://www.mirage.app">Mirage</a> in NYC. We're enabling people to tell stories in powerful new ways by making compelling, expressive video creation accessible through generative <a href="https://mirage.app/blog/seeing-voices">video</a>, <a href="https://mirage.app/blog/shaping-voices">audio</a>, and more.
      </p>
      <p>
        Before joining Mirage (formerly known as Captions), I was a Research Scientist at <a href="https://deepmind.google/">DeepMind</a>, where I developed the <a href="https://proceedings.mlr.press/v139/jaegle21a.html">Perceiver</a> <a href="https://arxiv.org/abs/2107.14795">family</a> <a href="https://arxiv.org/abs/2202.10890">of</a> <a href="https://proceedings.mlr.press/v162/hawthorne22a.html">architectures</a>, generative models for music and creative tools (<a href="https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/">Lyria</a>, <a href="https://blog.youtube/inside-youtube/ai-and-music-experiment/">Dream Track</a>, and <a href="https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/">Music AI Sandbox</a>), and generative models for <a href="https://proceedings.mlr.press/v139/jaegle21b.html">behavior</a> and <a href="https://arxiv.org/abs/1909.13789">physical systems</a>. I worked on computer vision and computational neuroscience at the <a href="https://www.upenn.edu">University of Pennsylvania</a>, where I did a PhD in the <a href="https://www.grasp.upenn.edu/">GRASP Lab</a> with <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a> and a postdoc with <a href="https://www.sas.upenn.edu/psych/rust-lab/">Nicole Rust</a>. While at Penn, I had the privilege to spend time in the labs of <a href="https://www.med.upenn.edu/apps/faculty/index.php/g275/p16954">Diego Contreras</a> and <a href="https://hosting.med.upenn.edu/hearing/">Maria Geffen</a> and with the <a href="https://cni.upenn.edu/">Computational Neuroscience Initiative</a>. During my PhD, I spent two wonderful summers at the <a href="https://is.mpg.de">Max-Planck Institute for Intelligent Systems</a>, working with <a href="https://scholar.google.com/citations?user=6NjbexEAAAAJ&hl=en">Michael Black</a> and <a href="https://scholar.google.com/citations?user=Wx62iOsAAAAJ&hl=en">Javier Romero</a>. I worked on consciousness and attention at the <a href="https://www.cuny.edu">City University of New York</a> with <a href="https://www.gc.cuny.edu/people/tony-ro">Tony Ro</a> and studied philosophy, music composition, and mathematics at <a href="https://www.tamu.edu">Texas A&M University</a>.
      </p>
      <p>
        Check out my <a href="https://scholar.google.com/citations?user=2iBYdwEAAAAJ&hl">Google Scholar</a> for a full list of publications.
      </p>
    </section>

    <hr>

    <section class="media">
      <h2>Talks & Media</h2>
      <ul class="media-list">
        <li>
          <a href="https://www.youtube.com/watch?v=JXEwCFyr-fg">Justin Tranter x Music AI | Google Lab Sessions</a>
          <span class="media-desc">— Artist incubator session with Grammy-nominated songwriter Justin Tranter</span>
        </li>
        <li>
          <a href="https://www.youtube.com/watch?v=wTZ3o36lXoQ">Stanford CS25: DeepMind's Perceiver and Perceiver IO</a>
          <span class="media-desc">— Stanford seminar on new data family architectures</span>
        </li>
        <li>
          <a href="https://www.youtube.com/watch?v=-DVbQV78Il8">Transformers at Work</a>
          <span class="media-desc">— Talk on practical applications of transformer architectures</span>
        </li>
        <li>
          <a href="https://www.youtube.com/watch?v=YBkOILybiNo">Perceivers: Towards General-Purpose Neural Network Architectures</a>
          <span class="media-desc">— London Machine Learning Meetup</span>
        </li>
        <li>
          <a href="https://deepmind.google/blog/perceiver-ar-general-purpose-long-context-autoregressive-generation/">Perceiver AR: General-Purpose Long-Context Autoregressive Generation</a>
          <span class="media-desc">— Google DeepMind Blog</span>
        </li>
        <li>
          <a href="https://magenta.withgoogle.com/perceiver-ar">Autoregressive Long-Context Music Generation with Perceiver AR</a>
          <span class="media-desc">— Google Magenta Blog</span>
        </li>
        <li>
          <a href="https://deepmind.google/blog/building-architectures-that-can-handle-the-worlds-data/">Building Architectures That Can Handle the World's Data</a>
          <span class="media-desc">— Google DeepMind Blog on Perceiver IO</span>
        </li>
      </ul>
    </section>

    <hr>

    <nav class="links">
      <a href="https://mailhide.io/e/FiftFvRB" target="_blank">Email</a>
      <span class="sep">|</span>
      <a href="https://scholar.google.com/citations?user=2iBYdwEAAAAJ&hl">Google Scholar</a>
      <span class="sep">|</span>
      <a href="https://twitter.com/drew_jaegle">Twitter</a>
      <span class="sep">|</span>
      <a href="https://www.linkedin.com/in/drew-jaegle-8064a8b">LinkedIn</a>
    </nav>
  </main>
</body>

</html>
